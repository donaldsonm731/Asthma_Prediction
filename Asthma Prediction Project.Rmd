---
title: "Asthma Attack Predictions"
author: "Kadie Iverson & Matthew Donaldson"
date: "2/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(car)
library(olsrr)
library(lme4)
```

lmer: reaction ~ days + (days|subject)

panel data

inter subject variability

generlaized linear model
 - randomness within the variance of the error term

lme4 package
glmer generalized mixed linear models



make sure to answer why we did what we did

TO DO:
  
- look into mixture model*** (lmer: reaction ~ days + (days|subject))

- Read panel data, (mixture model source)

- make a decision on whether to have data from each participant or hold out on 2 participants


Questions to answer: 

- What are our outliers? -> we looked at the categories against the cont. inputs                                               in a boxplot to find outliers outside of 1.5IQR. Then 
                            took any index that showed up more than once. 
                            
- We dont scale/ standardize the factored data do we?

Packages Used: 
- lme4
- caret
- car
- any others?

Sources:
- Mixture model: https://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/2Longitudinal.pdf
- Catet Package: https://topepo.github.io/caret/feature-selection-overview.html
- Vraible selection: https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
- Boxplots: http://www.unige.ch/ses/sococ/cl/r/bapr.e.html
- Regressing Cat. data: https://advstats.psychstat.org/book/mregression/catpredictor.php
- Coding Cat. Data: https://stats.oarc.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/
 
 
## Practicum of Data Analytics Project
################################################################################
##importing and data visualization
```{r}
# Importing the data set and printing the first 6 rows to see what it looks like
asthmaDataOriginal= read.csv("Asthma_Data_File.csv")
# Removing id number for each subject
asthmaData = data.frame(asthmaDataOriginal[,-2])
head(asthmaData)
dim(asthmaDataOriginal)
```
## Data Description
The first summary doesn't give us to much information because half the inputs are chr. So, before looking at the properties of each feature we need to convert the strings to integers.
```{r}
# Summary gives a description for each input and output, giving you a sense of what the data looks like
summary(asthmaData)
dim(asthmaData)
```
Removing the subject number and all the non categorical data. Then factoring each input.
Now there are levels for each categorical input.
```{r}
# Only want  to factor the categories so removing the columns listed below.
# These are: subject, temp, humidity, windspeed and ACTScore.
names = names(asthmaData[,c(-1,-8,-10,-12,-13)]) 
asthmaData[,names] = lapply(asthmaData[,names], factor)

str(asthmaData)


```
Bar plots and histograms give us an idea of the data in each category. 
,,, Exapand on observations...
```{r}
barplot(prop.table(table(asthmaData$Age)), main = 'Age')
barplot(prop.table(table(asthmaData$Gender)), main = 'Gender')
barplot(prop.table(table(asthmaData$OutdoorJob)), main = 'Out Door Job')
barplot(prop.table(table(asthmaData$OutdoorActivities)), main = 'Out Door Activities')
barplot(prop.table(table(asthmaData$SmokingHabit)), main = 'Smoking Habit')
barplot(prop.table(table(asthmaData$Pressure)), main = 'Pressure')
barplot(prop.table(table(asthmaData$UVIndex)), main = 'UV Index')

hist(asthmaData$Humidity, breaks = 25, main = 'Humidity')

hist(asthmaData$Temperature, breaks = 25, main = 'temp')

hist(asthmaData$WindSpeed, breaks = 25, main = 'wind')
hist(asthmaData$ACTScore,breaks = 25, main = 'ACT score')
```
Same here...
```{r}
table(asthmaData$Age) 
table(asthmaData$Gender)
table(asthmaData$OutdoorJob)
table(asthmaData$OutdoorActivities)
table(asthmaData$SmokingHabit)
table(asthmaData$Pressure)
table(asthmaData$UVIndex)
table(asthmaData$ACTScore)
```

#################################################################################
## Finding outliers in the categorical/numeric data
To find outliers, we will have a box plot of each input that is categorical and put it against the inputs that are continuous.

Finding the outliers using Boxplot (finds points outside 1.5*IQR), as well as to get a better understanding the distribution of the features a box plot was made. 


first plotting 1 categorical input at a time with temp humidity

```{r}
## NEED TO USE PACKAGE car for this to work because of the upper case B

# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outlires
# to keep track of when looking at other inputs that are continuous.

# Source for this: http://www.unige.ch/ses/sococ/cl/r/bapr.e.html

outlier_ageH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$Age,data=asthmaData, xlab = 'Age Category', ylab = 'Humidity (%)'))

outlier_genderH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$Gender,data=asthmaData))

outlier_smH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$SmokingHabit,data=asthmaData))

outlier_ODJH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$OutdoorJob,data=asthmaData))

outlier_ODAH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$OutdoorActivities,data=asthmaData))

outlier_pH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$Pressure,data=asthmaData))

outlier_UVH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$UVIndex,data=asthmaData))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_H = c(outlier_ageH, outlier_genderH, outlier_smH, outlier_ODJH, outlier_ODAH,outlier_pH, outlier_UVH)

table(totOutlier_H)
```
Next plotting 1 cat. at a time with 
```{r}
## NEED TO USE PACKAGE car for this to work because of the upper case B

# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outliers
# to keep track of when looking at other inputs that are continuous.
outlier_ageT = as.numeric(Boxplot(asthmaData$Temperature ~asthmaData$Age,data=asthmaData))

outlier_genderT = as.numeric(Boxplot(asthmaData$Temperature ~asthmaData$Gender,data=asthmaData))

outlier_smT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$SmokingHabit,data=asthmaData))

outlier_ODJT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$OutdoorJob,data=asthmaData))

outlier_ODAT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$OutdoorActivities,data=asthmaData))

outlier_pT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$Pressure,data=asthmaData))

outlier_UVT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$UVIndex,data=asthmaData))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_T= c(outlier_ageT, outlier_genderT, outlier_smT, outlier_ODJT, outlier_ODAT,outlier_pT, outlier_UVT)

table(totOutlier_T)
```

lastly, plotting 1 cat at a time with windspeed
```{r}
# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outliers
# to keep track of when looking at other inputs that are continuous.
outlier_ageW = as.numeric(Boxplot(asthmaData$WindSpeed ~asthmaData$Age,data=asthmaData))
#length(asthmaData$Age[outlier_ageW])/length(asthmaData$Age[asthmaData$Age == 4])



outlier_genderW = as.numeric(Boxplot(asthmaData$WindSpeed ~asthmaData$Gender,data=asthmaData))
#length(asthmaData$Gender[outlier_genderW])/length(asthmaData$Gender[asthmaData$Gender == 0])

outlier_smW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$SmokingHabit,data=asthmaData))

outlier_ODJW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$OutdoorJob,data=asthmaData))

outlier_ODAW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$OutdoorActivities,data=asthmaData))

outlier_pW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$Pressure,data=asthmaData))

outlier_UVW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$UVIndex,data=asthmaData))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_W = c(outlier_ageW, outlier_genderW, outlier_smW, outlier_ODJW, outlier_ODAW,outlier_pW, outlier_UVW)

table(totOutlier_W)

```

Looking at the total amount of outliers now:
```{r}
totOutliers = c(totOutlier_H, totOutlier_T, totOutlier_W)
#length(totOutliers)
#table(totOutliers)
#table(totOutliers) > 1
#which(table(totOutliers) > 1)

repOutliers = which(table(totOutliers) > 1) #Gives the indices for the the ones that show up more than once. 

# This ensures that if we run the code again it will not take more
# Data out, just noticed it was going down when this was not added
if(dim(asthmaData)[1] == dim(asthmaDataOriginal)[1]){
  asthmaData= asthmaData[-c(repOutliers),]
}
# Visual help that outliers are only removed once
dim(asthmaData)
length(repOutliers)
length(unique(totOutliers))
```

Check to see all inputs and categories are still represented
```{r}
# Age group aboce 50 lost 23 instances, not sig. for the group
# Males also lost 23 instances
# ODJ: Occationally lost 23 instances
# Extremely likely : lost 23 instances
# No smoking lost 23 instances
# Pressure 1007 lost 6 instances, 1008 lost 4,  1009 lost 2, 1010 lost 5
#            1011 lost 4, 1012 and 1013 lost 1 each (totalign 23 instances)
#UVindex: extreme lost 2 and the low lost 21.

## All in all, no group was lost or severly minimized during this process
table(asthmaData$Age) 
table(asthmaData$Gender)
table(asthmaData$OutdoorJob)
table(asthmaData$OutdoorActivities)
table(asthmaData$SmokingHabit)
table(asthmaData$Pressure)
table(asthmaData$UVIndex)
table(asthmaData$ACTScore)

```
#############################################################################
## Standardize Data set
```{r}
## Do we need to scale all inputs or just the non-factroized ones??
#asthmaData = as.numeric(asthmaData[,-13])
asthmaData$Humidity = rescale(asthmaData$Humidity, scale = TRUE)
asthmaData$Temperature = rescale(asthmaData$Temperature, scale = TRUE)
asthmaData$WindSpeed = rescale(asthmaData$WindSpeed, scale = TRUE)

```



###############################################################################
## By Subject plots
```{r}
subj1 = asthmaData[asthmaData$UserNo. == 1,]
subj2 = asthmaData[asthmaData$UserNo. == 2,]
subj3 = asthmaData[asthmaData$UserNo. == 3,]
subj4 = asthmaData[asthmaData$UserNo. == 4,]
subj5 = asthmaData[asthmaData$UserNo. == 5,]
subj6 = asthmaData[asthmaData$UserNo. == 6,]
subj7 = asthmaData[asthmaData$UserNo. == 7,]
subj8 = asthmaData[asthmaData$UserNo. == 8,]
subj9 = asthmaData[asthmaData$UserNo. == 9,]
subj10 = asthmaData[asthmaData$UserNo. == 10,]

sprintf('Number of Instances per Subject')
sprintf('Subject 1: %f',dim(subj1)[1])
sprintf('Subject 2: %f',dim(subj2)[1])
sprintf('Subject 3: %f',dim(subj3)[1])
sprintf('Subject 4: %f',dim(subj4)[1])
sprintf('Subject 5: %f',dim(subj5)[1])
sprintf('Subject 6: %f',dim(subj6)[1])
sprintf('Subject 7: %f',dim(subj7)[1])
sprintf('Subject 8: %f',dim(subj8)[1])
sprintf('Subject 9: %f',dim(subj9)[1])
sprintf('Subject 10: %f',dim(subj10)[1])


```


## ACTScore vs Temp by subject
```{r}
plot(subj1$Temperature,subj1$ACTScore)
plot(subj2$Temperature,subj2$ACTScore)
plot(subj3$Temperature,subj3$ACTScore)
plot(subj4$Temperature,subj4$ACTScore)
plot(subj5$Temperature,subj5$ACTScore)
plot(subj6$Temperature,subj6$ACTScore)
plot(subj7$Temperature,subj7$ACTScore)
plot(subj8$Temperature,subj8$ACTScore)
plot(subj9$Temperature,subj9$ACTScore)
plot(subj10$Temperature,subj10$ACTScore)
```


## ACTScore vs humidity by subject
```{r}
plot(subj1$Humidity,subj1$ACTScore)
plot(subj2$Humidity,subj2$ACTScore)
plot(subj3$Humidity,subj3$ACTScore)
plot(subj4$Humidity,subj4$ACTScore)
plot(subj5$Humidity,subj5$ACTScore)
plot(subj6$Humidity,subj6$ACTScore)
plot(subj7$Humidity,subj7$ACTScore)
plot(subj8$Humidity,subj8$ACTScore)
plot(subj9$Humidity,subj9$ACTScore)
plot(subj10$Humidity,subj10$ACTScore)
```

## ACTScore vs windspeed by subject 
```{r}
plot(subj1$WindSpeed,subj1$ACTScore)
plot(subj2$WindSpeed,subj2$ACTScore)
plot(subj3$WindSpeed,subj3$ACTScore)
plot(subj4$WindSpeed,subj4$ACTScore)
plot(subj5$WindSpeed,subj5$ACTScore)
plot(subj6$WindSpeed,subj6$ACTScore)
plot(subj7$WindSpeed,subj7$ACTScore)
plot(subj8$WindSpeed,subj8$ACTScore)
plot(subj9$WindSpeed,subj9$ACTScore)
plot(subj10$WindSpeed,subj10$ACTScore)
```

##############################################################################
## Training and Test Set
```{r}
# Train with leaving 3 people out
set.seed(3)

#index = createDataPartition(asthmaData, p = .75, list = FALSE)

#train = asthmaData[index,]
#test = asthmaData[-index,]

# This groups the data into k-folds, leaving out some of the patients
# to ensure more robust model.
subject = asthmaData$UserNo.
folds <- groupKFold(subject, k = 7) 



```

################################################################################
## Mixture Model
```{r}
train = asthmaData[folds$Fold1,]
# Catagorical Data
subject = train$UserNo.
loc = train$Location
gender = train$Gender
age = train$Age
ODJ = train$OutdoorJob
ODA = train$OutdoorActivities
smoking = train$SmokingHabit
pressure = train$Pressure
uv = train$UVIndex

# Continous Data
temp = train$Temperature
hum = train$Humidity
wind = train$WindSpeed

# Y value
ACT = train$ACTScore

```

The first model uses as many inputs as it can without getting a singular error and a random effect from the subjects. Model 2, same as 1 but now random effect is location. Model 3 also R.E. is location but with less variables.

The anova table below shows use which model is most significant.
```{r}
## To Do: below is just a example, need to re-do.
#fm1 <- lmer ( ACT ~ pressure +  ( smoking | subject ), data = train )
#summary(fm1)
## Baisc structure of lmer()
##  lmer(repsonce variable ~ fixed values (i.e. the different input features) + random effects(i.e. patients and/or location and/or gender ???))

# Conditional means of the random effects
model1 = lmer(ACT ~ gender + age + ODJ + ODA + smoking +  pressure  + temp + hum +  (1|subject), data = train )

model2 = lmer(ACT ~ (1|subject), data = train )

model3 = lmer(ACT ~ hum + (hum|subject), data = train )

#model2 = lmer(ACT ~ gender + age + ODJ + ODA + smoking +  pressure  + temp + hum +  (1|loc), data = asthmaData_train )

#model3 = lmer(ACT ~  ODJ + ODA + smoking +  pressure  + temp + hum +  (1|loc), data = train )

anova(model1,model2, model3)
summary(model1)
summary(model2)
summary(model3)
#summary(model2)
#rr2 <- ranef(fm1)
#rr2$subject
```



```{r}

set.seed(23)
train_control <- trainControl(method = "LOOCV")
model <- train(ACTScore ~., data = training_dataset,
               method = "lm",
               trControl = train_control)
print(model)

```



















##############################################################################
```{r}
# Catagorical Data
gender = asthmaData$Gender
age = asthmaData$Age
ODJ = asthmaData$OutdoorJob
ODA = asthmaData$OutdoorActivities
smoking = asthmaData$SmokingHabit
pressure = asthmaData$Pressure
uv = asthmaData$UVIndex

# Continous Data
temp = asthmaData$Temperature
hum = asthmaData$Humidity
wind = asthmaData$WindSpeed

# Y value
ACT = asthmaData$ACTScore

```


```{r}
barplot(prop.table(table(age)), main = 'Age')
barplot(prop.table(table(gender)), main = 'Gender')
barplot(prop.table(table(ODJ)), main = 'Out Door Job')
barplot(prop.table(table(ODA)), main = 'Out Door Activities')
barplot(prop.table(table(smoking)), main = 'Smoking Habit')
barplot(prop.table(table(pressure)), main = 'Pressure')
barplot(prop.table(table(uv)), main = 'UV Index')
#hist(age, breaks = 25)
#hist(gender, breaks = 25)
#hist(ODJ, breaks = 25)
#hist(ODA, breaks = 25)
#hist(smoking, breaks = 25)
hist(hum, breaks = 25, main = 'Humidity')
#hist(pressure, breaks = 25)
hist(temp, breaks = 25, main = 'temp')
#hist(uv, breaks = 25)
hist(wind, breaks = 25, main = 'wind')
hist(ACT,breaks = 25, main = 'ACT score')
```

```{r}
table(age) 
table(gender)
table(ODJ)
table(ODA)
table(smoking)
table(pressure)
table(uv)
table(ACT)
```
```{r}

which(asthmaData$Pressure == 1003)
which(asthmaData$Pressure == 1004)
which(asthmaData$ACT == 16)

```

#################################################################################
## Finding outliers in the categorical/numeric data
To find outliers, we will have a box plot of each input that is categorical and put it against the inputs that are continuous.

Finding the outliers using Boxplot (finds points outside 1.5*IQR), as well as to get a better understanding the distribution of the features a box plot was made. 


first plotting 1 categorical input at a time with temp humidity

```{r}
## NEED TO USE PACKAGE car for this to work because of the upper case B

# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outlires
# to keep track of when looking at other inputs that are continuous.

# Source for this: http://www.unige.ch/ses/sococ/cl/r/bapr.e.html

outlier_ageH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$Age,data=asthmaData))

outlier_genderH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$Gender,data=asthmaData))

outlier_smH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$SmokingHabit,data=asthmaData))

outlier_ODJH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$OutdoorJob,data=asthmaData))

outlier_ODAH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$OutdoorActivities,data=asthmaData))

outlier_pH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$Pressure,data=asthmaData))

outlier_UVH = as.numeric(Boxplot(asthmaData$Humidity~asthmaData$UVIndex,data=asthmaData))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_H = c(outlier_ageH, outlier_genderH, outlier_smH, outlier_ODJH, outlier_ODAH,outlier_pH, outlier_UVH)

table(totOutlier_H)
```


Next plotting 1 cat at a time with 
```{r}
## NEED TO USE PACKAGE car for this to work because of the upper case B

# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outliers
# to keep track of when looking at other inputs that are continuous.
outlier_ageT = as.numeric(Boxplot(asthmaData$Temperature ~asthmaData$Age,data=asthmaData))

outlier_genderT = as.numeric(Boxplot(asthmaData$Temperature ~asthmaData$Gender,data=asthmaData))

outlier_smT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$SmokingHabit,data=asthmaData))

outlier_ODJT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$OutdoorJob,data=asthmaData))

outlier_ODAT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$OutdoorActivities,data=asthmaData))

outlier_pT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$Pressure,data=asthmaData))

outlier_UVT = as.numeric(Boxplot(asthmaData$Temperature~asthmaData$UVIndex,data=asthmaData))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_T= c(outlier_ageT, outlier_genderT, outlier_smT, outlier_ODJT, outlier_ODAT,outlier_pT, outlier_UVT)

table(totOutlier_T)
```

lastly, plotting 1 cat at a time with windspeed
```{r}
# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outliers
# to keep track of when looking at other inputs that are continuous.
outlier_ageW = as.numeric(Boxplot(asthmaData$WindSpeed ~asthmaData$Age,data=asthmaData))
#length(asthmaData$Age[outlier_ageW])/length(asthmaData$Age[asthmaData$Age == 4])



outlier_genderW = as.numeric(Boxplot(asthmaData$WindSpeed ~asthmaData$Gender,data=asthmaData))
#length(asthmaData$Gender[outlier_genderW])/length(asthmaData$Gender[asthmaData$Gender == 0])

outlier_smW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$SmokingHabit,data=asthmaData))

outlier_ODJW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$OutdoorJob,data=asthmaData))

outlier_ODAW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$OutdoorActivities,data=asthmaData))

outlier_pW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$Pressure,data=asthmaData))

outlier_UVW = as.numeric(Boxplot(asthmaData$WindSpeed~asthmaData$UVIndex,data=asthmaData))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_W = c(outlier_ageW, outlier_genderW, outlier_smW, outlier_ODJW, outlier_ODAW,outlier_pW, outlier_UVW)

table(totOutlier_W)

```

Looking at the total amount of outliers now:
```{r}
totOutliers = c(totOutlier_H, totOutlier_T, totOutlier_W)
#length(totOutliers)
#table(totOutliers)
#table(totOutliers) > 1
#which(table(totOutliers) > 1)

repOutliers = which(table(totOutliers) > 1) #Gives the indices for the the ones that show up more than once. 

# This ensures that if we run the code again it will not take more
# Data out, just noticed it was going down when this was not added
if(dim(asthmaData)[1] == dim(asthmaDataOriginal)[1]){
  asthmaData_reduced = asthmaData[-c(repOutliers),]
}
# Visual help that outliers are only removed once
dim(asthmaData_reduced)
length(repOutliers)
```

```{r}
# Catagorical Data
gender = asthmaData_reduced$Gender
age = asthmaData_reduced$Age
ODJ = asthmaData_reduced$OutdoorJob
ODA = asthmaData_reduced$OutdoorActivities
smoking = asthmaData_reduced$SmokingHabit
pressure = asthmaData_reduced$Pressure
uv = asthmaData_reduced$UVIndex

# Continuous Data
temp = asthmaData_reduced$Temperature
hum = asthmaData_reduced$Humidity
wind = asthmaData_reduced$WindSpeed

# Y value
ACT = asthmaData_reduced$ACTScore
```


Visual Check that not to much data was lost in any one category for each input
```{r}

#hist(asthmaData$Age, breaks = 25)
#hist(asthmaData$Gender, breaks = 25)
#hist(asthmaData$OutdoorJob, breaks = 25)
#hist(asthmaData$OutdoorActivities, breaks = 25)
#hist(asthmaData$SmokingHabit, breaks = 25)
#hist(asthmaData$Humidity, breaks = 25)
#hist(asthmaData$Pressure, breaks = 25)
#hist(asthmaData$Temperature, breaks = 25)
#hist(asthmaData$UVIndex, breaks = 25)
#hist(asthmaData$WindSpeed, breaks = 25)
```


################################################################################\
## USING Factor function and 
# https://stats.oarc.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/

```{r}
# helpful reference
# https://advstats.psychstat.org/book/mregression/catpredictor.php

gender = factor(gender)#,c(0,1), labels=c('male', 'female'))
age = factor(age)#,c(0,1,2,3), labels=c('19-30', '31-40','41-50', 'above 50'))
ODJ = factor(ODJ)#,c(0,1,2), labels=c('frequently', 'occationally', 'rarely'))
ODA = factor(ODA)#,c(0,1,2), labels=c('extremly Likely', 'neither', 'not likely'))
smoking = factor(smoking)#,c(0,1), labels=c('no', 'yes'))
pressure = factor(pressure)#,c(0,1,2,3,4,5,6,7,8,9,10,11), labels=c('1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012','1013','1014'))
uv = factor(uv)#, c(0,1), labels=c('extreme', 'low'))

# Contrasts converts to number for each level
#contrasts(asthmaData$Gender)
#a.c = contrasts(age.f)
#contrasts(ODJ.f)
#contrasts(ODA.f)
#contrasts(smoking)
#contrasts(pressure.f)
#contrasts(uv.f)

#levels(asthmaData$Gender)
#levels(asthmaData$Age)
#levels(asthmaData$UVIndex)


#names = names(asthmaData[,c(-6,-8,-10)])
#asthmaData[,names] = lapply(asthmaData[,names], factor)

#str(asthmaData)
```



```{r}
summary(lm(ACT ~ temp + hum + wind + gender + age + ODJ + ODA + smoking + pressure + uv), data = train)
```

noticing which values are insignificant, we are now looking at the variables that 
only had significance. We are only taking out Pressure and Temp, bc don't know how to take away part of an input, or if that is even a valid procedure.
```{r}
summary(lm(ACT ~ hum + wind + gender + age + ODJ + ODA + smoking  + uv, data = train))

```




###############################################################################
## Splitting the data set into training and testing
```{r}
set.seed(3)
index = createDataPartition(asthmaData$ACTScore, p = .75, list = FALSE)

train = asthmaData[index,]
test = asthmaData[-index,]

```

## Training on Linear Regression Model
```{r}
# no parameter tuning
set.seed(5)
fit = lm(ACTScore ~ ., data = train)

summary(fit)
```


#Exhaustive Search
```{r}
a <- ols_step_best_subset(fit)
#b <- ols_step_all_possible(fit)

a
plot(a)
#plot(b)

# Below Functions can be used when parameter tuning is needed
#fitControl = trainControl(method = 'repeatedcv',number  = 5, repeats = 10)
#fit = train(ACTScore ~ ., data = train, method = 'lm', trControl = fitControl)
```


```{r}
fit.lm <- lm(ACT ~ temp + hum + wind + gender + age + ODJ + ODA + smoking + pressure + uv)
c <- ols_step_best_subset(fit.lm)
#d <- ols_step_all_possible(fit.lm)

c
plot(c)
```










## OUTDated models and ideas like lm() without factoring
######################################################################

```{r}
### Converting all strings to integers ###

## Can access a certain column either by a their name or column number
#asthmaData['ACTScore']
#asthmaData[14]
#asthmaData$SmokingHabit

###################################################################

## Changing age
asthmaData$Age[asthmaData$Age == 'Above 50'] = 4 
asthmaData$Age[asthmaData$Age == '41-50'] = 3
asthmaData$Age[asthmaData$Age == '31-40'] = 2 
asthmaData$Age[asthmaData$Age == '19-30'] = 1

## The above transformation still kept elements as char so 'as.integer' converts the char to int
asthmaData$Age = as.integer(asthmaData$Age)

# Gender,  binary, yes = 1 and no = 0
## DOES IT MATTER IF WE CHOOSE 0 AND 1 or -1 AND 1 ??????????????????????
asthmaData$Gender[asthmaData$Gender == 'Female'] = 1
asthmaData$Gender[asthmaData$Gender == 'Male'] = 0

asthmaData$Gender = as.integer(asthmaData$Gender)

# changing outdoor job
asthmaData$OutdoorJob[asthmaData$OutdoorJob == 'Frequently'] = 3
asthmaData$OutdoorJob[asthmaData$OutdoorJob == 'Occasionally'] = 2
asthmaData$OutdoorJob[asthmaData$OutdoorJob == 'Rarely'] = 1

asthmaData$OutdoorJob = as.integer(asthmaData$OutdoorJob)

# Outdoor activity
asthmaData$OutdoorActivities[asthmaData$OutdoorActivities == 'Extremely likely'] = 3
asthmaData$OutdoorActivities[asthmaData$OutdoorActivities == 'Neither likely or dislikely'] = 2
asthmaData$OutdoorActivities[asthmaData$OutdoorActivities == 'Not at all likely'] = 1

asthmaData$OutdoorActivities = as.integer(asthmaData$OutdoorActivities)
# Since smoking was binary, yes = 1 and no = 0
asthmaData$SmokingHabit[asthmaData$SmokingHabit == "Yes"] = 1
asthmaData$SmokingHabit[asthmaData$SmokingHabit == "No"] = 0

asthmaData$SmokingHabit = as.integer(asthmaData$SmokingHabit)
# UV Index, binary
asthmaData$UVIndex[asthmaData$UVIndex == 'Extreme'] = 1
asthmaData$UVIndex[asthmaData$UVIndex == 'Low'] = 0

asthmaData$UVIndex = as.integer(asthmaData$UVIndex)
```
Lastly, A correlation matrix and heat map were made to get a sense on how dependent each input was with one another. A couple of the most important observations are that gender and age seem to have a strong negative correlation while others like out door activate and age don't have much correlation. Note the method used shows linear dependence, so the data may share a higher order dependence. 

```{r}
library(corrplot)
cor = cor(asthmaData, method = c("pearson", "kendall", "spearman"))
corrplot(cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

heatmap(cor, sym = TRUE)
```


```{r}
pairs(asthmaData)
```

Once all the data is converted into integers a summary is then done again to get some information out of the features.
```{r}

str(asthmaData) # str is nice because it gives type of each input
summary(asthmaData) # Summary is good to see median, mean, min, max...
```

As seen in the summary above, out door job, pressure and temperature seem to be the only features that have almost the same mean and median. This tells us that a lot of our data is not normally distributed. Also, it will be important to keep in mind that some of this data is binary while other are have discrete categories like out door activities which can carry values 1,2 or 3. 

Another way to check to see how the data is distributed is by looking at a histogram. Below in the histograms shows that the many of the data features are in deed not normal and most actually are discrete. One important part to notice here is that temperature doesn't actually follow a normal distribution as assumed earlier from the summary statistics. Also, interestingly enough, the humidity data looks to have a heavy left tail with the bulk of the data being on the right side, which is reflected in the summary above as the median is higher than the mean. 

###################################################################
```{r}
boxplot(asthmaData$Humidity~asthmaData$Age,data=asthmaData)
boxplot(asthmaData$Humidity~asthmaData$Gender,data=asthmaData)
boxplot(asthmaData$Humidity~asthmaData$SmokingHabit,data=asthmaData)
boxplot(asthmaData$Humidity~asthmaData$OutdoorJob,data=asthmaData)
boxplot(asthmaData$Humidity~asthmaData$OutdoorActivities,data=asthmaData)
boxplot(asthmaData$Humidity~asthmaData$Pressure,data=asthmaData)
boxplot(asthmaData$Humidity~asthmaData$UVIndex,data=asthmaData)
```
```{r}
# Focusing on the boxplots with the cirlces
# First start with out door job and humidity

index_ODJ2 = which(asthmaData$OutdoorJob == 2)
q1 = quantile(asthmaData$Humidity[index_ODJ2], 0.25)
q3 = quantile(asthmaData$Humidity[index_ODJ2], 0.75)

IQR = q3 - q1
lowerWhisker_ODJ = q1 - 1.5*IQR

index_outliers_ODJ = which(asthmaData$Humidity[index_ODJ2] < lowerWhisker)

index_outliers_ODJ
```

```{r}
# Next Age
index_Age = which(asthmaData$Age == 3)
q1 = quantile(asthmaData$Humidity[index_Age], 0.25)
q3 = quantile(asthmaData$Humidity[index_Age], 0.75)

IQR = q3 - q1
lowerWhisker_Age = q1 - 1.5*IQR

index_outliers_Age = which(asthmaData$Humidity[index_Age] < lowerWhisker_Age)

index_outliers_Age

```


```{r}
# Next smoking
index_SM2 = which(asthmaData$SmokingHabit == 0)
q1 = quantile(asthmaData$Humidity[index_SM2], 0.25)
q3 = quantile(asthmaData$Humidity[index_SM2], 0.75)

IQR = q3 - q1
lowerWhisker_SM = q1 - 1.5*IQR

index_outliers_SM = which(asthmaData$Humidity[index_SM2] < lowerWhisker_SM)

index_outliers_SM

```

```{r}
# Next pressure
cat = c(1007, 1010, 1011, 1013)
index_outliers_p = vector(length = length(cat))
for (i in 1:length(cat)){
  index_p = which(asthmaData$Pressure == cat[i])
  q1 = quantile(asthmaData$Humidity[index_p], 0.25)
  q3 = quantile(asthmaData$Humidity[index_p], 0.75)

  IQR = q3 - q1
  lowerWhisker_p = q1 - 1.5*IQR

  index_outliers_p = combine(index_outliers_p,which(asthmaData$Humidity[index_p] < lowerWhisker_p))
}

index_outliers_p

```


################################################################################
## OUTLIER DETECTION METHODS

```{r}
library(OutlierDetection)
library(OutliersO3)
library(outliers)
```


# OUtlier Detection
# -Note: all the univariate statistical tests were excluded from this because  
#  our data inputs are correlated
# I don't think distance should be used here because we are working in a high dimension But kept them in to discuss.


Depth-based Approach:
```{r}
X <- asthmaData[,1:10]

Y <- depthout(X,cutoff=0.03) # This yields about 3% of our data as outliers
D <- Y$`Location of Outlier`
D
```

Mahalanobis Distance

```{r}
Y <- maha(X,cutoff=0.95)
E <- Y$`Location of Outlier`
E
```

k Nearest Neighbours Distance method

```{r}

Y <- nn(X,k=5)
K <- Y$`Location of Outlier`
K
```


kth Nearest Neighbour Distance method

```{r}

Y <- nnk(X,k=5)
G <- Y$`Location of Outlier`
G
```


```{r}
intersect(K,G)
```

Outlier detection using Robust Kernal-based Outlier Factor(RKOF) algorithm

```{r}

Y <- dens(X,k=4,C=1)
H <- Y$`Location of Outlier`
H
```


Outlier detection using generalised dispersion

```{r}

Y <- disp(X,cutoff=0.99)
I <- Y$`Location of Outlier`
I
```
```{r}
intersect(I,H)

```


Joint assessment of outlier detection methods

```{r}

Y <- OutlierDetection(X,depth = TRUE,dens = TRUE)
J <- Y$`Location of Outlier`
J
```

c) Report outlier based on consensus rule based on all the techniques that applied to your data sets.


```{r}
out_list <- append(A, B)
out_list <- append(out_list, C)
out_list <- append(out_list, D)
out_list <- append(out_list, E)
out_list <- append(out_list, K)
out_list <- append(out_list, G)
out_list <- append(out_list, H)
out_list <- append(out_list, I)
out_list <- append(out_list, J)

length(out_list)
```


```{r}
L <- as.data.frame(table(out_list))
M <- L$Freq > 5
N <- which(M == TRUE)
length(N)
```


################################################################################
## PCA Analysis

```{r}
####  Step 1: Standardization ####
# This standardizes the data with z = (value - mean)/sd
#head(asthmaData[,1:10])
asthmaData_scaled = scale(asthmaData[,1:10]) # This standardizes the input data 
#summary(asthmaData_scaled) # Checking standardization

#### Step 2: Finding Cov matrix ####
cov_matrix = cov(asthmaData_scaled)
#cov_matrix # Checking cov_matrix
```


```{r}
#### Step 3: Computing eigen values and eigenvectors of Cov-matrix to identify principle components ###
eigen = eigen(cov_matrix)
# eigen$vectors and eigen$values for the vectors and values
#eigen$values # Looks like the eigen values are already ordered

#### Step 4: Seeing percentage of variance accounted for by each comp. ####
plot(eigen$values)
```

```{r}
#### Selecting amount of features we want #### 

# First find the percent variance in each 
sum_eig = sum(eigen$values)
per_var = eigen$values/sum_eig
#print(per_var) # Gives percentage of variance in each component
# We will select amount of components that gives us at least 95% of the variance

# From the output this can be seen to be the first 8 eigen values.
#sum(per_var[0:7])

featureVector = eigen$vectors # Getting features we want
#dim(asthmaData_scaled)
#dim(featureVector)
asthmaData.pca = asthmaData_scaled %*% featureVector # Transforming Data

## Adding the output column back in
asthmaData.pca = cbind(asthmaData.pca, asthmaData[,11])

```

```{r}
#### Checking work from above #### 

#asthmaData.pca<-princomp(asthmaData_scaled[])
#plot(asthmaData.pca, main="Proportions of variance explained by the components")


```

###############################################################################
# Outlier detetion on Transformed data
```{r}
#head(asthmaData.pca)
x = asthmaData.pca[,1:10]
y = dens(x,k=4,C=1)
y$`Location of Outlier`

```


```{r}
# generalized dispersion
ol = disp(x,cutoff=0.05)
ol$`Location of Outlier`

```

```{r}
index = OutlierDetection(x)$`Location of Outlier`


```




################################################################################

## Trying a multivariate linear regression
```{r}
# y = b0 + b1*v1 + b2*v2 ... + bn*vn
set.seed(24)
#head(asthmaData.pca)
## Creating and training and test data set.
#dt = sort(sample(nrow(asthmaData.pca), nrow(asthmaData.pca)*.7))
size = 0.75*nrow(asthmaData.pca)
numRows = dim(asthmaData.pca)[1]

training_index = sort(sample(numRows, size, replace = FALSE, prob = NULL))
test_index = setdiff(1:numRows,training_index)

xTrain = asthmaData.pca[training_index,1:10]
yTrain = asthmaData.pca[training_index,11]
xTest = asthmaData.pca[test_index,1:10]
yTest = asthmaData.pca[test_index,11]
```



# Making a fit
```{r}
v1 = xTrain[,1]
v2 = xTrain[,2]
v3 = xTrain[,3]
v4 = xTrain[,4]
v5 = xTrain[,5]
v6 = xTrain[,6]
v7 = xTrain[,7]
v8 = xTrain[,8]
v9 = xTrain[,9]
v10 = xTrain[,10]


y = yTrain

fit = lm(y ~ v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10)

summary(fit)
```
```{r}
#Residuals
resid = fit$residuals
#R^2 value
r_sq = summary(fit)$r.squared
# F-Test Statistic
F_stat = summary(fit)$fstat
# C.I. for regression CO
coef_CI = confint(fit)

# Note the outputs below give an insight into how our model is doing. 
# we see an r^2 or 0.674
anova(fit)

#print(sum((resid)^2))
#print(r_sq)
#print(F_stat)
print(coef_CI)

#vcov(fit) # Last one is interesting to see, bc using PCA they should be around 0
```

## Predicting Values and MSE
Note the MSE can be seen from the ANOVA table, just done for practice
```{r}

b0 = fit$coefficients[1]
b = fit$coefficients[2:11]
x = xTest
#dim(x)

y_pred = b0 + x %*% b 
head(y_pred,6)
# MSE
#sum((y_pred - yTrain)^2)

```

```{r}
# Testing Prediction with r function, the prediction is the same...
# But look at how big the prediction interval is!!!
#xTest[1,]
newdata = data.frame(xTest)
#xTest[1,1], + xTest[1,2], + xTest[1,3], + xTest[1,4], + xTest[1,5], + xTest[1,6], + xTest[1,7], + xTest[1,8], + xTest[1,9], + xTest[1,10]
predictions = predict(fit,newdata,interval = "prediction")
head(predictions)
```


```{r}
# Getting MSE of our predicted values
y_true = test[,8]
y_predicted = predictions[1,]
y_predicted
#error = y_true - y_predicted
#MSE = sum(error^2)
#MSE


```


#################################################################################
Looking at Random Forest
```{r}
library(randomForest)
fit_rf = randomForest(train[,1:7], train[,8])

y_pred_rf = predict(fit_rf,test[,1:7])

#y_pred_rf[1]
#test[1,8]
### MSE
MSE_rf = sum((y_pred_rf - test[,8])^2)

diff = (round(y_pred_rf) - test[,8])^2
length(diff[diff == 0]) # Number of correct classifications
```

#######################################################
Cross-Valdidation

```{r}
set.seed(23)
random_sample <- createDataPartition(asthmaData$ACTScore,
                                p = 0.7, list = FALSE)
training_dataset  <- asthmaData[random_sample, ]
testing_dataset <- asthmaData[-random_sample, ]
model <- lm(ACTScore ~., data = training_dataset)
predictions <- predict(model, testing_dataset)

data.frame( R2 = R2(predictions, testing_dataset $ ACTScore),
            RMSE = RMSE(predictions, testing_dataset $ ACTScore),
            MAE = MAE(predictions, testing_dataset $ ACTScore))
```

```{r}
set.seed(23)
train_control <- trainControl(method = "LOOCV")
model <- train(ACTScore ~., data = training_dataset,
               method = "lm",
               trControl = train_control)
print(model)
```


```{r}
set.seed(23)
train_control <- trainControl(method = "cv",
                              number = 10)
model <- train(ACTScore ~., data = training_dataset,
               method = "lm",
               trControl = train_control)
print(model)
#model$finalmodel
```

```{r}
predict(model$finalModel, newdata = data.frame(testing_dataset), interval = "prediction")
```



```{r}
set.seed(23)
train_control <- trainControl(method = "repeatedcv",
                            number = 10, repeats = 3)
model <- train(ACTScore ~., data = training_dataset,
               method = "lm",
               trControl = train_control)
print(model)
#model$finalmodel
```