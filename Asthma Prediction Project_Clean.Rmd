---
title: "Asthma Attack Predictions"
author: "Kadie Iverson & Matthew Donaldson"
date: "2/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(car)
library(olsrr)
library(lme4)
library(shiny)
library(cvms)
library(groupdata2)
library(lmerTest)

#install.packages(c("boot", "car", "caret", "tidyverse",  "effects", "foreign", 
                   #"Hmisc", "DT", "knitr", "lme4", "MASS", "mlogit", "msm", 
                   #"QuantPsyc", "reshape2", "rms", "sandwich", "sfsmisc", "sjPlot", 
                   #"vcd", "visreg", "MuMIn", "lmerTest", "shiny"))
```


--> how each subject rates their asthma
--> look at the type of factoring (maybe 0,1,2)
--> standardized after split into training

lmer: reaction ~ days + (days|subject)

generalized linear model
 - randomness within the variance of the error term

TO DO:
  
- In lmerTest package function to use: step.lmerNodLmerTest() -> backward elimination of Rand/fixed effects

- Also ANOVA() tests rand effects and drop1() tests fixed effects (f-test).

- Read panel data, (mixture model source)

- make a decision on whether to have data from each participant or hold out on 2 participants

Sources:
- Mixture model: https://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/2Longitudinal.pdf
- Catet Package: https://topepo.github.io/caret/feature-selection-overview.html
- Vraible selection: https://cran.r-project.org/web/packages/olsrr/vignettes/variable_selection.html
- Boxplots: http://www.unige.ch/ses/sococ/cl/r/bapr.e.html
- Regressing Cat. data: https://advstats.psychstat.org/book/mregression/catpredictor.php
- Coding Cat. Data: https://stats.oarc.ucla.edu/r/modules/coding-for-categorical-variables-in-regression-models/
 


 
# Practicum of Data Analytics Project

## Importing
```{r}
asthmaDataOriginal= read.csv("Asthma_Data_File.csv")  # Importing the data set 

asthmaData = data.frame(asthmaDataOriginal[,-2])  # Removing id number for each subject

head(asthmaData)  #Looking at the first 6 entries
dim(asthmaData)
```


### Data Description

The first summary doesn't give us to much information because half the inputs are chr. So, before looking at the properties of each feature we need to convert the strings to integers.

```{r}
# Summary gives a description for each input and output, giving you a sense of what the data looks like
summary(asthmaData)
```

Removing the subject number and all the non categorical data. Then factoring each input.
Now there are levels for each categorical input.

```{r}
# Only want  to factor the categories so removing the columns listed below.
# These are: temp, humidity, windspeed and ACTScore.
names = names(asthmaData[,c(-8,-10,-12,-13)]) 
asthmaData[,names] = lapply(asthmaData[,names], factor)

str(asthmaData)

contrasts(asthmaData$Location)
```



Bar plots and histograms give us an idea of the data in each category. 
```{r}
barplot(prop.table(table(asthmaData$UserNo.)), main = 'Subject')
barplot(prop.table(table(asthmaData$Age)), main = 'Age')
barplot(prop.table(table(asthmaData$Gender)), main = 'Gender')
barplot(prop.table(table(asthmaData$OutdoorJob)), main = 'Out Door Job')
barplot(prop.table(table(asthmaData$OutdoorActivities)), main = 'Out Door Activities')
barplot(prop.table(table(asthmaData$SmokingHabit)), main = 'Smoking Habit')
barplot(prop.table(table(asthmaData$Pressure)), main = 'Pressure')
barplot(prop.table(table(asthmaData$UVIndex)), main = 'UV Index')

hist(asthmaData$Humidity, breaks = 25, main = 'Humidity')
hist(asthmaData$Temperature, breaks = 25, main = 'temp')
hist(asthmaData$WindSpeed, breaks = 25, main = 'wind')
hist(asthmaData$ACTScore,breaks = 17, main = 'ACT score')
```


```{r}
table(asthmaData$Age) 
table(asthmaData$Gender)
table(asthmaData$OutdoorJob)
table(asthmaData$OutdoorActivities)
table(asthmaData$SmokingHabit)
table(asthmaData$Pressure)
table(asthmaData$UVIndex)
table(asthmaData$ACTScore)
```

Looking at frequency and distribution of the ACT score that each user self reported.

```{r}
ggplot(asthmaData, aes(x = ACTScore)) +
  geom_histogram(fill = "white", colour = "black", bins = 20) +
  facet_grid(UserNo. ~ .)
```

```{r}
#t1 = c(164, 172, 168, 177, 156, 195)
#t2 = c(178, 191, 197, 182, 185, 177)
#t3 = c(175, 193, 178, 171, 163, 176)
#t4 = c(155, 166, 149, 164, 170, 168)

#val = c(t1, t2, t3, t4)
#fac = gl(n=4, k=6, labels=c('type1', 'type2', 'type3', 'type4'))

#aov1 = aov(asthmaData$ACTScore ~ asthmaData$Age)
#summary(aov1)

#aov2 = aov(asthmaData$ACTScore ~ asthmaData$WindSpeed)
#summary(aov2)

library('rcompanion')
cramerV(asthmaData$OutdoorJob, asthmaData$OutdoorActivities, bias.correct = FALSE)
cramerV(asthmaData$SmokingHabit, asthmaData$Gender, bias.correct = FALSE)
```


## Splitting into Train & Test

```{r}
set.seed(28)

groups <-        # Randomly assign train/test groups to all values of UserNo.
  asthmaData %>%
  select(UserNo.) %>%
  distinct(UserNo.) %>%
  rowwise() %>%
  mutate(group = sample(
    c("train", "test"),
    1,
    replace = TRUE,
    prob = c(0.8, 0.2) 
  ))

groups

# Join group assignments to my_dat
asthmaData <- asthmaData %>%
  left_join(groups)

train = filter(asthmaData, group == "train")
test = filter(asthmaData, group == "test")

dim(train)
```

```{r}
# Train Set
# Catagorical Data
subject = train$UserNo.
loc = train$Location
gender = train$Gender
age = train$Age
ODJ = train$OutdoorJob
ODA = train$OutdoorActivities
smoking = train$SmokingHabit
pressure = train$Pressure
uv = train$UVIndex
# Continous Data
temp = train$Temperature
hum = train$Humidity
wind = train$WindSpeed
# Y value
ACT = train$ACTScore

# Test Set
# Catagorical Data
test_subject = test$UserNo.
test_loc = test$Location
test_gender = test$Gender
test_age = test$Age
test_ODJ = test$OutdoorJob
test_ODA = test$OutdoorActivities
test_smoking = test$SmokingHabit
test_pressure = test$Pressure
test_uv = test$UVIndex
# Continous Data
test_temp = test$Temperature
test_hum = test$Humidity
test_wind = test$WindSpeed
# Y value
test_ACT = test$ACTScore
```


## Finding outliers in the categorical/numeric data
To find outliers, we will have a box plot of each input that is categorical and put it against the inputs that are continuous.Finding the outliers using Boxplot (finds points outside 1.5*IQR), as well as to get a better understanding the distribution of the features a box plot was made. We do this for each, train and test, set.

First plotting 1 categorical input at a time with temp humidity

```{r}
## NEED TO USE PACKAGE car for this to work because of the upper case B

# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outlires
# to keep track of when looking at other inputs that are continuous.

# Source for this: http://www.unige.ch/ses/sococ/cl/r/bapr.e.html

outlier_ageH = as.numeric(Boxplot(hum~age))
outlier_genderH = as.numeric(Boxplot(hum~gender))
outlier_smH = as.numeric(Boxplot(hum~smoking))
outlier_ODJH = as.numeric(Boxplot(hum~ODJ))
outlier_ODAH = as.numeric(Boxplot(hum~ODA))
outlier_pH = as.numeric(Boxplot(hum~pressure))
outlier_UVH = as.numeric(Boxplot(hum~uv))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_H = c(outlier_ageH, outlier_genderH, outlier_smH, outlier_ODJH, outlier_ODAH,outlier_pH, outlier_UVH)
table(totOutlier_H)
```

Next plotting 1 cat. at a time with 
```{r}
## NEED TO USE PACKAGE car for this to work because of the upper case B

# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outliers
# to keep track of when looking at other inputs that are continuous.

outlier_ageT = as.numeric(Boxplot(temp~age))
outlier_genderT = as.numeric(Boxplot(temp~gender))
outlier_smT = as.numeric(Boxplot(temp~smoking))
outlier_ODJT = as.numeric(Boxplot(temp~ODJ))
outlier_ODAT = as.numeric(Boxplot(temp~ODA))
outlier_pT = as.numeric(Boxplot(temp~pressure))
outlier_UVT = as.numeric(Boxplot(temp~uv))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out
totOutlier_T= c(outlier_ageT, outlier_genderT, outlier_smT, outlier_ODJT, outlier_ODAT,outlier_pT, outlier_UVT)

table(totOutlier_T)
```

lastly, plotting 1 cat at a time with windspeed
```{r}
# This box and whisker plot created the boxplot and also labels the points that are 
# 1.5 times outside the IQR, I then take those points, convert them from chr to
# numberic and store it as an outlier. I think take the union of all the outliers
# to keep track of when looking at other inputs that are continuous.

outlier_ageW = as.numeric(Boxplot(wind~age))
outlier_genderW = as.numeric(Boxplot(wind~gender))
outlier_smW = as.numeric(Boxplot(wind~smoking))
outlier_ODJW = as.numeric(Boxplot(wind~ODJ))
outlier_ODAW = as.numeric(Boxplot(wind~ODA))
outlier_pW = as.numeric(Boxplot(wind~pressure))
outlier_UVW = as.numeric(Boxplot(wind~uv))

# The last part combines all the outlier indices found as a vector and keeps all 
# number once, so say 114 is stored twice then the unique() will just take one 
# of them out

totOutlier_W = c(outlier_ageW, outlier_genderW, outlier_smW, outlier_ODJW, outlier_ODAW,outlier_pW, outlier_UVW)
table(totOutlier_W)

```

Looking at the total amount of outliers now:
```{r}
totOutliers = c(totOutlier_H, totOutlier_T, totOutlier_W)
#length(totOutliers)
#table(totOutliers)
#table(totOutliers) > 1
#which(table(totOutliers) > 1)

repOutliers = which(table(totOutliers) > 1) #Gives the indices for the the ones that show up more than once. 

# This ensures that if we run the code again it will not take more
# Data out, just noticed it was going down when this was not added
if(dim(train)[1] == 757){
  train= train[-c(repOutliers),]
}
# Visual help that outliers are only removed once
dim(asthmaData)
dim(test)
dim(train)
length(repOutliers)
length(unique(totOutliers))
```

Check to see all inputs and categories are still represented
```{r}
# Age group above 50 lost 23 instances, not sig. for the group
# Males also lost 23 instances
# ODJ: Occationally lost 23 instances
# Extremely likely : lost 23 instances
# No smoking lost 23 instances
# Pressure 1007 lost 6 instances, 1008 lost 4,  1009 lost 2, 1010 lost 5
#            1011 lost 4, 1012 and 1013 lost 1 each (totalign 23 instances)
#UVindex: extreme lost 2 and the low lost 21.

## All in all, no group was lost or severly minimized during this process
table(asthmaData$Age) 
table(asthmaData$Gender)
table(asthmaData$OutdoorJob)
table(asthmaData$OutdoorActivities)
table(asthmaData$SmokingHabit)
table(asthmaData$Pressure)
table(asthmaData$UVIndex)
table(asthmaData$ACTScore)

```



## Standardize Data set
```{r}
## standard normalize of continuous variable for mixture model.
hum = scale(hum, scale = TRUE)
temp = scale(temp, scale = TRUE)
wind = scale(wind, scale = TRUE)

test_hum = scale(test_hum, scale = TRUE)
test_temp = scale(test_temp, scale = TRUE)
test_wind = scale(test_wind, scale = TRUE)
```







## Mixted Effects Model
### Intial lmer Models
The first model uses as many inputs as it can without getting a singular error and a random effect from the subjects. Model 2, same as 1 but now random effect is location. Model 3 also R.E. is location but with less variables.

The AIC score below shows use which model is most significant. between fixed effects model and which random effects model. Fro this we can see by adding random effects, it lowers the AIC scorem, telling us the random effects help.
```{r}
# Conditional means of the random effects
model1 = glm(ACT ~ 1, data = train)
model2 = lmer(ACT ~ (1|subject), data = train )
model3 = lmer(ACT ~ (1|loc), data = train)
model4 = lmer(ACT ~ (1|subject) + (1| loc), data = train)

AIC(model1)
AIC(model2)
AIC(model3)
AIC(model4)


```


### Backward feature selection

```{r}
backmodel1 <- lmer(ACT ~ (1|subject), data = train)

step_res1 <- step(backmodel1)
final1 <- get_model(step_res1)
anova(final1)
step_res1
```

```{r}
backmodel2 <- lmer(ACT ~  wind + gender + age + ODJ + ODA + smoking +  pressure  + temp + hum +  (1|subject) + (1|loc), data = train)

step_res2 <- step(backmodel2)
final2 <- get_model(step_res2)
anova(final2)
step_res2
```


```{r}
backmodel3 <- lmer(ACT ~  wind + gender + ODJ + ODA + pressure + hum +  (1|subject) + (1|loc), data = train)

step_res3 <- step(backmodel3)
final3 <- get_model(step_res3)
anova(final3)
step_res3
```

```{r}
backmodel4 <- lmer(ACT ~  wind + gender + ODJ  + pressure + hum +  (1|subject), data = train)

step_res4 <- step(backmodel4)
final4 <- get_model(step_res4)
anova(final4)
step_res4
```

Here
```{r}
library(MuMIn)
AIC(final2)
AIC(backmodel4)
AIC(backmodel3)

summary(final2)$r.squared
r.squaredGLMM(backmodel4)
r.squaredGLMM(backmodel3)


# installed rcompanion and MuMIn

```


```{r}
library(tidyverse)
library(caret)
library(car)
library(olsrr)
library(lme4)
library(shiny)
library(cvms)
library(groupdata2)   # fold() partition()
library(knitr)        # kable()
library(dplyr)        # %>% arrange()
library(ggplot2)
set.seed(7)


# Fold data 
train = fold(data = train, k = 3,
            id_col = 'UserNo.',num_fold_cols = 1,handle_existing_fold_cols = "keep") %>%
            arrange(.folds)
            

train %>% head(15) %>% kable()
```

```{r}

### Note: for some reason age is a problem in this
mixed_model_formulas <- c("ACTScore ~ (1|UserNo.) + (1|Location)",
                          "ACTScore ~ WindSpeed + Gender + OutdoorJob + OutdoorActivities + Pressure +                                        Humidity+(1|UserNo.) + (1|Location)",
                          "ACTScore ~ WindSpeed + Gender + OutdoorJob + OutdoorActivities + Pressure +                                        Humidity",
                          "ACTScore ~ SmokingHabit")


CV <- cross_validate(data = train,
  formulas = mixed_model_formulas,
  fold_cols = '.folds',
  family = 'gaussian',
  REML = FALSE,
  preprocessing = "standardize")

par(mfrow=c(1,2))
plot(CV$RMSE)
plot(CV$AIC)
```



```{r}

library("lattice")
library("merTools")

bestModel = lmer(score ~ temp + hum  + uv + ws + gender + (1|subj) + (1|loc), data = asthmaData)


#summary(bestModel)
#dotplot(ranef(bestModel, condVar = TRUE))

preds = predictInterval(bestModel, n.sims = 500, level = 0.9, stat = 'median')
#head(preds)

```


```{r}

plot(bestModel, subj ~ resid(.), abline = 0 ) # generate diagnostic plots
plot(bestModel, loc ~ resid(.), abline = 0 ) # generate diagnostic plots

plot(bestModel, resid(., type = "pearson") ~ fitted(.) | subj, id = 0.05, 
     adj = -0.3, pch = 20, col = "gray40", cex = .5)

plot(bestModel, resid(., type = "pearson") ~ fitted(.) | loc, id = 0.05, 
     adj = -0.3, pch = 20, col = "gray40", cex = .5)

```


